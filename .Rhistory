?set.seed
# install.packages("C50")
library(C50)
install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
# 選擇建模變數
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
# sample
?sample
sample(1:10)
sample(1:10, size = 5)
sample(c(0,1), size= 10, replace = T)  # 取後放回
sample.int(20, 12) # 兩個參數都要放整數，此例為取1:20中的12個不重複樣本
set.seed(2)
# 把資料分成 1:training data 和 2:testing data
ind <- sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
table(ind) / nrow(churnTrain)
table(ind) / nrow(churnTest)
table(sample(x = 1:2,size = 100, replace=T))
set.seed(1)
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
a = c(1,2,3,4,5,6,7,8,9)
ind = c(1,0,1,0,1,0,1,0,1)
ind == 1
a[ind == 1]
a[ind == 0]
set.seed(2)
runif(2)
runif(2)
runif(2)
set.seed(2)
runif(2)
set.seed(2)
runif(2)
set.seed(1)
runif(2)
set.seed(1)
runif(2)
set.seed(2)
runif(2)
install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
# 選擇建模變數
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
# sample
?sample
sample(1:10)
sample(1:10, size = 5)
sample(c(0,1), size= 10, replace = T)  # 取後放回
sample.int(20, 12) # 兩個參數都要放整數，此例為取1:20中的12個不重複樣本
# 通常產生亂數序列希望是不會重復的。實際上，R 在現在操作視窗下，第一次產生時亂數時，從當下時間 (current time)，生成一個種子 (seed) 出發，不斷迭代更新產生隨機均等分配亂數 (uniform random number)，所以不同時間下執行 R，啟用不同的種子，隨後內部的隨機種子就已經改變了。
# 模擬亂數是不會重復的，有時我們需要模擬結果是可重復的亂數序列，此時需要用函式 set.seed()，在每次產生偽隨機亂數之前，把種子設定種子為某一特定正整數即可。
set.seed(2)
# 把資料分成 1:training data 和 2:testing data
ind <- sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
table(ind) / nrow(churnTrain)
table(sample(x = 1:2,size = 100, replace=T))
set.seed(1)
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
a = c(1,2,3,4,5,6,7,8,9)
ind = c(1,0,1,0,1,0,1,0,1)
ind == 1
a[ind == 1]
a[ind == 0]
install.packages('rpart')
library('rpart')
# 使用rpart(CART)建立決策樹模型
churn.rp <- rpart(churn ~ ., data=trainset)
churn.rp
summary(churn.rp)
con = rpart.control(cp=0.01)
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)
# 畫出決策樹
par(mfrow = c(1,1))
plot(churn.rp, margin=0.1)
plot(churn.rp, uniform=TRUE,branch = 0.6, margin=0.1)
?plot.rpart
text(churn.rp)
text(churn.rp, all=TRUE, use.n=TRUE)
printcp(churn.rp)
plotcp(churn.rp)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(churn.rp)
# 找出minimum cross-validation errors
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
# 將churn.cp設為臨界值來修剪樹
prune.tree = prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions <- predict(prune.tree, testset,type = "class")
table(testset$churn, predictions)
install.packages('caret')
install.packages('e1071')
library('caret')
library('e1071')
confusionMatrix(table(predictions, testset$churn))
?confusionMatrix
install.packages("party")
library('party')
ctree.model = ctree(churn ~ . , data = trainset)
plot(ctree.model, margin=0.1)
daycharge.model = ctree(churn ~ total_day_charge + international_plan, data = trainset)
plot(daycharge.model)
ctree.predict = predict(ctree.model ,testset)
table(ctree.predict, testset$churn)
confusionMatrix(table(ctree.predict, testset$churn))
# install.packages("C50")
library(C50)
c50.model = C5.0(churn ~., data=trainset)
?C5.0Control
c=C5.0Control(minCases = 20)
c50.model = C5.0(churn ~., data=trainset,control = c)
summary(c50.model)
plot(c50.model)
c50.predict = predict(c50.model,testset)
table(c50.predict, testset$churn)
confusionMatrix(table(c50.predict, testset$churn))
ind = cut(1:nrow(churnTrain), breaks=10, labels=F)
ind
accuracies = c()
for (i in 1:10) {
fit = rpart(formula=churn ~., data=churnTrain[ind != i,])
predictions = predict(fit, churnTrain[ind == i, ! names(churnTrain) %in% c("churn")], type="class")
correct_count = sum(predictions == churnTrain[ind == i,c("churn")])
accuracies = append(correct_count / nrow(churnTrain[ind == i,]), accuracies)
}
accuracies
mean(accuracies)
install.packages("caret")
library(caret)
control=trainControl(method="repeatedcv", number=10, repeats=3)
model =train(churn~., data=trainset, method="rpart", trControl=control)
model
predictions = predict(model, testset)
table(predictions,testset$churn)
library('caret')
importance = varImp(model, scale=FALSE)
importance
plot(importance)
install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc<-predictions[, 1]
head(pred.to.roc)
pred.rocr<-prediction(pred.to.roc, testset$churn)
pred.rocr
perf.rocr<-performance(pred.rocr, measure ="auc", x.measure="cutoff")
perf.tpr.rocr<-performance(pred.rocr, "tpr","fpr")
plot(perf.tpr.rocr,colorize=T,main=paste("AUC:",(perf.rocr@y.values)))
# rpart
library('rpart')
churn.rp<-rpart(churn ~., data=trainset)
# ctree
install.packages("party")
library('party')
ctree.model = ctree(churn ~ . , data = trainset)
# C5.0
library(C50)
c50.model = C5.0(churn ~., data=trainset)
rp.predict.prob = predict(churn.rp, testset,type='prob')
c50.predict.prob = predict(c50.model,testset,type='prob')
ctree.predict.prob = sapply(predict(ctree.model ,testset,type='prob'),function(e){unlist(e)[1]})
rp.prediction = prediction(rp.predict.prob[,1],testset$churn)
c50.prediction = prediction(c50.predict.prob[,1],testset$churn)
ctree.prediction = prediction(ctree.predict.prob,testset$churn)
rp.performance = performance(rp.prediction, "tpr","fpr")
c50.performance = performance(c50.prediction, "tpr","fpr")
ctree.performance = performance(ctree.prediction, "tpr","fpr")
plot(rp.performance,col='red')
plot(c50.performance, add=T,col='green')
plot(ctree.performance, add=T,col='blue')
install.packages("party")
install.packages("caret")
install.packages("caret")
printcp(churn.rp)
library(C50)
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
set.seed(2)
ind <- sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
table(sample(x = 1:2,size = 100, replace=T))
library('rpart')
churn.rp <- rpart(churn ~ ., data=trainset)
chrun.rp
churn.rp
summary(churn.rp)
summary(churn.rp)
con = rpart.control(cp=0.01)
churn.rp<-rpart(churn ~., data=trainset,control = con)
# install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
# 選擇建模變數
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
# sample
?sample
sample(1:10)
sample(1:10, size = 5)
sample(c(0,1), size= 10, replace = T)  # 取後放回
sample.int(20, 12) # 兩個參數都要放整數，此例為取1:20中的12個不重複樣本
# 通常產生亂數序列希望是不會重復的。實際上，R 在現在操作視窗下，第一次產生時亂數時，從當下時間 (current time)，生成一個種子 (seed) 出發，不斷迭代更新產生隨機均等分配亂數 (uniform random number)，所以不同時間下執行 R，啟用不同的種子，隨後內部的隨機種子就已經改變了。
# 模擬亂數是不會重復的，有時我們需要模擬結果是可重復的亂數序列，此時需要用函式 set.seed()，在每次產生偽隨機亂數之前，把種子設定種子為某一特定正整數即可。
set.seed(2)
# 把資料分成 1:training data 和 2:testing data
ind <- sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
table(ind) / nrow(churnTrain)
table(sample(x = 1:2,size = 100, replace=T))
set.seed(1)
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
a = c(1,2,3,4,5,6,7,8,9)
ind = c(1,0,1,0,1,0,1,0,1)
ind == 1
a[ind == 1]
a[ind == 0]
# install.packages('rpart')
library('rpart')
# 使用rpart(CART)建立決策樹模型
churn.rp <- rpart(churn ~ ., data=trainset)
churn.rp
summary(churn.rp)
con = rpart.control(cp=0.01)
?rpart.control
churn.rp <- rpart(churn ~., data=trainset,control = con)
# 畫出決策樹
par(mfrow = c(1,1))
plot(churn.rp, margin=0.1)
plot(churn.rp, uniform=TRUE,branch = 0.6, margin=0.1)
?plot.rpart
text(churn.rp)
text(churn.rp, all=TRUE, use.n=TRUE)
printcp(churn.rp)
plotcp(churn.rp)
printcp(churn.rp)
plotcp(churn.rp)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(churn.rp)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(churn.rp)
library('caret')
install.packages('caret')
install.packages("caret")
install.packages('caret')
install.packages('e1071')
install.packages('e1071')
library('caret')
library('e1071')
library('ggplot2')
library('lattice')
library('caret')
confusionMatrix(table(predictions, testset$churn))
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
prune.tree = prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions <- predict(prune.tree, testset,type = "class")
table(testset$churn, predictions)
confusionMatrix(table(predictions, testset$churn))
?confusionMatrix
install.packages("party")
library('party')
library('party')
ctree.model = ctree(churn ~ . , data = trainset)
plot(ctree.model, margin=0.1)
daycharge.model = ctree(churn ~ total_day_charge + international_plan, data = trainset)
plot(daycharge.model)
ctree.predict = predict(ctree.model ,testset)
table(ctree.predict, testset$churn)
confusionMatrix(table(ctree.predict, testset$churn))
library(C50)
c50.model = C5.0(churn ~., data=trainset)
c=C5.0Control(minCases = 20)
c50.model = C5.0(churn ~., data=trainset,control = c)
summary(c50.model)
plot(c50.model)
c50.predict = predict(c50.model,testset)
table(c50.predict, testset$churn)
confusionMatrix(table(c50.predict, testset$churn))
ind = cut(1:nrow(churnTrain), breaks=10, labels=F)
ind
accuracies = c()
for (i in 1:10) {
fit = rpart(formula=churn ~., data=churnTrain[ind != i,])
predictions = predict(fit, churnTrain[ind == i, ! names(churnTrain) %in% c("churn")], type="class")
correct_count = sum(predictions == churnTrain[ind == i,c("churn")])
accuracies = append(correct_count / nrow(churnTrain[ind == i,]), accuracies)
}
library(rpart)
accuracies
mean(accuracies)
accuracies = c()
for (i in 1:10) {
fit = rpart(formula=churn ~., data=churnTrain[ind != i,])
predictions = predict(fit, churnTrain[ind == i, ! names(churnTrain) %in% c("churn")], type="class")
correct_count = sum(predictions == churnTrain[ind == i,c("churn")])
accuracies = append(correct_count / nrow(churnTrain[ind == i,]), accuracies)
}
accuracies
mean(accuracies)
library(caret)
control=trainControl(method="repeatedcv", number=10, repeats=3)
model = train(churn~., data=trainset, method="rpart", trControl=control)
model
predictions = predict(model, testset)
table(predictions,testset$churn)
# install.packages("caret")
library(caret)
control = trainControl(method="repeatedcv", number=10, repeats=3)
model = train(churn~., data=trainset, method="rpart", trControl=control)
model
predictions = predict(model, testset)
table(predictions,testset$churn)
importance = varImp(model, scale=FALSE)
importance
plot(importance)
install.packages("rminer")
# install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc <- predictions[, 1]
head(pred.to.roc)
pred.rocr <- prediction(pred.to.roc, testset$churn)
pred.rocr
perf.rocr <- performance(pred.rocr, measure ="auc", x.measure="cutoff")
perf.tpr.rocr <- performance(pred.rocr, "tpr","fpr")
plot(perf.tpr.rocr,colorize=T,main=paste("AUC:",(perf.rocr@y.values)))
set.seed(1)
rnif(5)
runif(5)
runif(5)
set.seed(1)
runif(5)
runif(5)
runif(5)
set.seed(1)
runif(5)
set.seed(72)
runif(5)
runif(5)
runif(5)
set.seed(72)
runif(5)
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc <- predictions[, 1]
head(pred.to.roc)
prediction(pred.to.roc, testset$churn)
pred.rocr <- prediction(pred.to.roc, testset$churn)
perf.rocr <- performance(pred.rocr, measure ="auc", x.measure="cutoff")
perf.tpr.rocr <- performance(pred.rocr, "tpr","fpr")
plot(perf.tpr.rocr,colorize=T, main=paste("AUC:",(perf.rocr@y.values)))
plot(perf.tpr.rocr,
colorize=T)
plot(perf.tpr.rocr,
colorize=T)
plot(perf.tpr.rocr,colorize=T, main=paste("AUC:",(perf.rocr@y.values)))
plot(perf.tpr.rocr,
colorize=T)
plot(perf.tpr.rocr,colorize=T, main=paste("AUC:",(perf.rocr@y.values)))
performance(pred.rocr, measure ="auc", x.measure="cutoff")
perf.rocr@y.values
perf.rocr@x.values
perf.rocr
